name: CI/CD Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  build-and-test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        node-version: [18.x]
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    # Backend Build
    - name: Setup Node.js (Backend)
      uses: actions/setup-node@v3
      with:
        node-version: ${{ matrix.node-version }}
        cache: 'npm'
        cache-dependency-path: backend/package-lock.json
    - name: Install Backend Dependencies
      run: |
        cd backend
        npm ci

    # Frontend Build
    - name: Setup Node.js (Frontend)
      uses: actions/setup-node@v3
      with:
        node-version: ${{ matrix.node-version }}
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json
    - name: Install Frontend Dependencies
      run: |
        cd frontend
        npm ci
    - name: Build Frontend
      run: |
        cd frontend
        npm run build

  docker-build-and-push:
    needs: build-and-test
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Log in to the Container registry
        uses: docker/login-action@v2
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Lowercase Repo Owner
        run: |
          echo "REPO_OWNER=$(echo ${{ github.repository_owner }} | tr '[:upper:]' '[:lower:]')" >> $GITHUB_ENV

      - name: Build and Push Backend
        uses: docker/build-push-action@v4
        with:
          context: ./backend
          push: true
          tags: ghcr.io/${{ env.REPO_OWNER }}/fooddelivery-backend:latest



  deploy:
    needs: docker-build-and-push
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Copy docker-compose to EC2
        uses: appleboy/scp-action@master
        with:
          host: ${{ secrets.EC2_HOST }}
          username: ${{ secrets.EC2_USER }}
          key: ${{ secrets.EC2_SSH_KEY }}
          source: "docker-compose.yml"
          target: "/home/${{ secrets.EC2_USER }}/app"

      - name: Deploy to EC2
        uses: appleboy/ssh-action@master
        with:
          host: ${{ secrets.EC2_HOST }}
          username: ${{ secrets.EC2_USER }}
          key: ${{ secrets.EC2_SSH_KEY }}
          script: |
            # Detect OS and install Docker
            if command -v apt-get &> /dev/null; then
               # Ubuntu/Debian
               if ! command -v docker &> /dev/null; then
                   echo "Installing Docker (apt)..."
                   sudo apt-get update
                   sudo apt-get install -y docker.io
                   sudo usermod -aG docker ${{ secrets.EC2_USER }}
               fi
               if ! command -v docker-compose &> /dev/null; then
                   sudo apt-get install -y docker-compose
               fi
            elif command -v yum &> /dev/null; then
               # Amazon Linux / CentOS
               if ! command -v docker &> /dev/null; then
                   echo "Installing Docker (yum)..."
                   sudo yum update -y
                   sudo yum install -y docker
                   sudo service docker start
                   sudo usermod -aG docker ${{ secrets.EC2_USER }}
               fi
               # Install docker-compose via binary for Amazon Linux
               if ! command -v docker-compose &> /dev/null; then
                   echo "Installing Docker Compose (binary)..."
                   sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
                   sudo chmod +x /usr/local/bin/docker-compose
                   # Ensure it's in path
                   if ! command -v docker-compose &> /dev/null; then
                       sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose
                   fi
               fi
            else
               echo "Unsupported Package Manager. Please install Docker manually."
               exit 1
            fi

            mkdir -p /home/${{ secrets.EC2_USER }}/app
            cd /home/${{ secrets.EC2_USER }}/app
            
            # Create/Update .env file with secrets
            echo "NODE_ENV=production" > .env
            
            # Update source code for manual dev server usage
            # Check if git exists and repo is initialized
            if [ -d .git ]; then
                echo "Updating source code..."
                git fetch origin main
                git reset --hard origin/main
            else
                echo "Cloning repository..."
                # Clone is tricky with auth, assuming public or https with token. 
                # Since we are already in the directory, we might skip full clone if not set up.
                # Just skipping if not a git repo to avoid errors.
                echo "Not a git repository. Skipping source update."
            fi

            echo "MONGO_URI=${{ secrets.MONGO_URI }}" >> .env
            echo "JWT_SECRET=${{ secrets.JWT_SECRET }}" >> .env
            echo "JWT_EXPIRE=30d" >> .env
            echo "FRONTEND_URL=${{ secrets.FRONTEND_URL }}" >> .env
            echo "EMAIL_SERVICE=${{ secrets.EMAIL_SERVICE }}" >> .env
            echo "EMAIL_USER=${{ secrets.EMAIL_USER }}" >> .env
            echo "EMAIL_PASS=${{ secrets.EMAIL_PASS }}" >> .env
            # AWS Configuration (Role-based auth)
            echo "AWS_REGION=${{ secrets.AWS_REGION }}" >> .env
            echo "AWS_BUCKET_NAME=${{ secrets.AWS_BUCKET_NAME }}" >> .env
            # Add other secrets as needed e.g., EMAIL_USER, etc.

            # Login to GHCR on EC2 (as root/sudo to ensure docker access)
            echo ${{ secrets.GITHUB_TOKEN }} | sudo docker login ghcr.io -u ${{ github.actor }} --password-stdin

            # Pull latest images
            sudo docker-compose pull

            # Restart containers
            sudo docker-compose up -d --remove-orphans

  deploy-frontend-s3:
    needs: build-and-test
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18.x'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install Dependencies
        run: |
          cd frontend
          npm ci

      - name: Build Frontend
        env:
          VITE_API_URL: /api
        run: |
          cd frontend
          npm run build

      - name: Copy build to EC2
        uses: appleboy/scp-action@master
        with:
          host: ${{ secrets.EC2_HOST }}
          username: ${{ secrets.EC2_USER }}
          key: ${{ secrets.EC2_SSH_KEY }}
          source: "frontend/dist"
          target: "/home/${{ secrets.EC2_USER }}/frontend-deploy-temp"

      - name: Deploy to S3 via EC2
        uses: appleboy/ssh-action@master
        with:
          host: ${{ secrets.EC2_HOST }}
          username: ${{ secrets.EC2_USER }}
          key: ${{ secrets.EC2_SSH_KEY }}
          script: |
            # Ensure AWS CLI is installed
            if ! command -v aws &> /dev/null; then
              sudo yum install -y aws-cli || sudo apt-get install -y awscli
            fi

            # Sync to S3 using EC2's IAM Role
            # Note: scp-action preserves structure, so path is .../frontend-deploy-temp/frontend/dist
            
            echo "=== DEBUG: Listing deploy directory ==="
            ls -R /home/${{ secrets.EC2_USER }}/frontend-deploy-temp
            echo "======================================="

            aws s3 sync /home/${{ secrets.EC2_USER }}/frontend-deploy-temp/frontend/dist s3://${{ secrets.AWS_FRONTEND_BUCKET_NAME }} --delete

            # Invalidate CloudFront Cache (if Distribution ID is provided)
            # We use a conditional check to avoid failure if the secret is missing
            if [ ! -z "${{ secrets.CLOUDFRONT_DISTRIBUTION_ID }}" ]; then
                echo "Invalidating CloudFront Cache..."
                aws cloudfront create-invalidation --distribution-id ${{ secrets.CLOUDFRONT_DISTRIBUTION_ID }} --paths "/*"
            else
                echo "Skipping CloudFront Invalidation (Secret CLOUDFRONT_DISTRIBUTION_ID not set)"
            fi

            # Cleanup
            rm -rf /home/${{ secrets.EC2_USER }}/frontend-deploy-temp
